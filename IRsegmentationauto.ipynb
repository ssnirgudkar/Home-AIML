{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IRsegmentationauto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RHzIlSvPEfJYhudeqt_p1y-p2ZyzDOaE",
      "authorship_tag": "ABX9TyOHDHw4iq0TwDP4kYwygJih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssnirgudkar/Home-AIML/blob/main/IRsegmentationauto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5-y0oWlvgdH"
      },
      "source": [
        "pip install --upgrade segments-ai\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e7NOkOfxDZW"
      },
      "source": [
        "from segments import SegmentsClient\n",
        "api_key = \"a89182567b17766b91773021b18d04574cd75109\"\n",
        "client = SegmentsClient(api_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_gzNefkxFty"
      },
      "source": [
        "dataset_identifier = \"ssnirgudkar/PilotIR\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsMCMIDtyQtR"
      },
      "source": [
        "#commenting this for now, since this will just give all the data sets available in my login\n",
        "#dataset = client.get_dataset(dataset_identifier)\n",
        "#print(dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moYug8I_xWM7"
      },
      "source": [
        "from segments import SegmentsDataset\n",
        "from segments.utils import export_dataset\n",
        "\n",
        "# Initialize a SegmentsDataset from the release file. We will train using these 100 images (although they are 7 classes)\n",
        "release_file = client.get_release(dataset_identifier,'V2.0')\n",
        "#print(release_file)\n",
        "releasedataset = SegmentsDataset(release_file, labelset='segmentation', filter_by='labeled')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFYoMO_z3Aln"
      },
      "source": [
        "#install dependencies for detectron 2\n",
        "!pip install pyyaml==5.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__,torch.cuda.is_available())\n",
        "!gcc --version\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBrRV1hC5RNB"
      },
      "source": [
        "#install detectron2 (Colab has CUDA 10.1 + torch 1.8)\n",
        "import torch \n",
        "assert torch.__version__.startswith(\"1.8\") #need to manually install 1.8 only if colab changes it's default version. as we see above, the default is 1.8 rt now\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi3g9Xfh6e6f"
      },
      "source": [
        "#setup logger for detectron2 \n",
        "import detectron2 \n",
        "from detectron2.utils.logger import setup_logger \n",
        "setup_logger()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDvOAhHoxuus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dadadc7-9413-46ac-b7d3-d91b1d546d32"
      },
      "source": [
        "\n",
        "#clone segments.ai repo for their utils code \n",
        "!git clone https://github.com/segments-ai/fast-labeling-workflow/\n",
        "%cd fast-labeling-workflow\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fast-labeling-workflow'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 76 (delta 43), reused 27 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n",
            "/content/fast-labeling-workflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_86CvUp9VT4"
      },
      "source": [
        "from segments import SegmentsDataset\n",
        "from segments.utils import export_dataset\n",
        "\n",
        "# Initialize a SegmentsDataset from the release file\n",
        "release_file = client.get_release(dataset_identifier,'V2.0')\n",
        "#print(release_file)\n",
        "releasedataset = SegmentsDataset(release_file, labelset='segmentation', filter_by='labeled')\n",
        "from utils import train_model\n",
        "model = train_model(releasedataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGLiTJuJI2Dr"
      },
      "source": [
        "#should save the model somewhere so it doesn't have to be recreated eachtime. this did not work\n",
        "#model.save('/content/drive/MyDrive/Models/detectronwithir')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT3bTuCyErKr"
      },
      "source": [
        "dataset_identifier_infer = \"ssnirgudkar/IRGray-100-set2-3classes\"\n",
        "dataset_infer = client.get_dataset(dataset_identifier_infer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHwnBangFVB0"
      },
      "source": [
        "infer_release_file = client.get_release(dataset_identifier_infer,'Fortestingraw1')\n",
        "infer_releasedataset = SegmentsDataset(infer_release_file, labelset='ground-truth', filter_by='unlabeled')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDwfYGC2Gpc-"
      },
      "source": [
        "from segments import SegmentsDataset\n",
        "from segments.utils import export_dataset\n",
        "from segments.utils import bitmap2file\n",
        "\n",
        "import cv2 \n",
        "import numpy as np \n",
        "import os \n",
        "from utils import visualize \n",
        "#this needs 3 channel image. so had to convert grayscale IR to RGB - 3 channels by copying the same pixel value on all 3\n",
        "#add logic to check if the image is 1 channel, and if so convert it to 3 channel\n",
        "for sample in infer_releasedataset:\n",
        "   infer_image = sample['image'] \n",
        "      \n",
        "   #imgcv = cv2.imread(infer_image)\n",
        "   #assert not isinstance(imgcv,type(None)), 'image not found'\n",
        "   #print (\"file read = {0}\".format(imgcv))\n",
        "   print(os.getcwd())  # prints current working directory\n",
        "   #infer_image2 = RemoveAlphaChannel[infer_image, White]\n",
        "   #4channel CYMK image is not taken by detectron. it needs 3 channels. so converting to RGB. we can add a conditional check\n",
        "   # to first check if it's 4 channels and then convert only if it is\n",
        "   infer_image2 = infer_image.convert(\"RGB\")\n",
        "   segmentation_bitmap, annotations = model(infer_image2)\n",
        "   print(\"segmentation bitmap executed\")\n",
        "   #visualize the predictions \n",
        "   visualize(infer_image2, segmentation_bitmap)\n",
        "   print(annotations)\n",
        "\n",
        "# Upload the predictions to Segments.ai so that we can check the effectiveness of auto labels\n",
        "   file = bitmap2file(segmentation_bitmap)\n",
        "   asset = client.upload_asset(file, 'label.png')    \n",
        "   attributes = {\n",
        "        'format_version': '0.1',\n",
        "        'annotations': annotations,\n",
        "        'segmentation_bitmap': { 'url': asset['url'] },\n",
        "   }\n",
        "   client.add_label(sample['uuid'], 'ground-truth', attributes, label_status='PRELABELED')\n",
        "   \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuhdIaEKIRgR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbfszMkT7QUa"
      },
      "source": [
        "import cv2 \n",
        "image1 = '/content/drive/MyDrive/Models/MVI_1463_NIR_RF_1_Ins.png' #singapore ir png\n",
        "image2 = '/content/drive/MyDrive/Models/1603391862.128166_color.png' #personal 2nd set ir color 3 channels png\n",
        "image3 = '/content/drive/MyDrive/Models/MVI_0797_VIS_OB.png' #singapore rgb\n",
        "image4 = '/content/drive/MyDrive/Models/1602782428.150594.png' #personal 1st set \n",
        "\n",
        "img1 = cv2.imread(image2,cv2.IMREAD_UNCHANGED)\n",
        "assert not isinstance(img1,type(None)), 'image not found'\n",
        "#print (\"file read = {0}\".format(img1))\n",
        "print (img1.shape)\n",
        "print(img1[1,:])\n",
        "#height,width, channel = img1.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}